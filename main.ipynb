{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Analysis of Image Deblurring Methods Performance Across Classical and AI-Based Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem statement\n",
    "\n",
    "In the field of image processing, the degradation of image quality due to various types of distorions poses significant challenges for both human interpretation and machine learning applications. This project aims to systematically investigate blur image distortions by statistically analyzing relationships between parameters of the blurred images and metrics of the deblurring methods, both classical and AI-based. We will build the dataset by evaluating multiple AI models alongside classical deblurring methods applying various blur types to the real-world image datasets. \n",
    "\n",
    "The results will be analyzed statistically to identify the most effective deblurring method and to understand the relationship between blur types, image parameters, and method performance. This analysis will provide insights into the robustness of deblurring algorithms and All code and the dataset generated during this project will be open-sourced to foster further research and development in the field of image restoration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of the dataset\n",
    "\n",
    "> 1. **HQ-50K Dataset**\n",
    ">\n",
    ">    - **Source:** HQ-50K is a large-scale dataset designed for image restoration tasks.\n",
    ">    - **Number of Observations:** 50,000 high-quality images for training and 1,250 test images.\n",
    ">    - **Variables per Observation:** Includes metadata such as texture details, semantic categories, and degradation levels.\n",
    ">    - **Type of Variables:** Image resolution, blur intensity (quantitative), noise level (quantitative), and semantic category (categorical)[[paper]]> (https://arxiv.org/abs/2306.05390)[[github]](https://github.com/littleYaang/HQ-50K)[[huggingface]](https://huggingface.co/datasets/YangQiee/HQ-50K).\n",
    ">\n",
    "> 2. **MC-Blur Dataset**\n",
    ">\n",
    ">    - **Source:** A dataset specifically constructed for image deblurring with four types of blur: uniform, motion, heavy defocus, and real-world blurs.\n",
    ">    - **Number of Observations:** Images collected from over 1,000 diverse scenes.\n",
    ">    - **Variables per Observation:** Blur type (categorical), blur intensity (quantitative), scene type (categorical)[[github]](https://github.com/HDCVLab/MC-Blur-Dataset).\n",
    ">\n",
    "> 3. **LSDIR Dataset**\n",
    ">    - **Source:** A large-scale dataset for image restoration tasks collected from Flickr.\n",
    ">    - **Number of Observations:** 84,991 training images and 2,000 validation/test images.\n",
    ">    - **Variables per Observation:** Noise level (quantitative), blur score (quantitative), resolution (quantitative)[[paper]](https://openaccess.thecvf.com/content/CVPR2023W/NTIRE/html/Li_LSDIR_A_Large_Scale_Dataset_for_Image_Restoration_CVPRW_2023_paper.html)[[github]](https://github.com/ofsoundof/LSDIR).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleanup\n",
    "\n",
    "> - Address formatting errors in metadata or file paths.\n",
    "> - Handle missing or repeated values in variables such as blur intensity or noise level.\n",
    "> - Remove noisy observations that might distort analysis results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "> - Merge subsets if using multiple datasets (e.g., training and test sets).\n",
    "> - Convert units where necessary (e.g., pixel intensity normalization).\n",
    "> - Define derived variables like restoration error metrics or blur-to-noise ratios.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration\n",
    "\n",
    "> 1. Perform descriptive statistics on key variables:\n",
    ">\n",
    "> - Mean and standard deviation of blur intensities.\n",
    "> - Distribution of noise levels across different categories.\n",
    ">\n",
    "> 2. Visualize data using:\n",
    ">\n",
    "> - Histograms for noise levels.\n",
    "> - Scatterplots showing relationships between blur intensity and restoration error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis testing\n",
    "\n",
    "> Examples of hypotheses to test:\n",
    ">\n",
    "> - Does motion blur result in higher restoration errors compared to uniform blur?\n",
    "> - Is there a significant difference in restoration accuracy between neural networks and classical methods?\n",
    "> - Does higher noise level correlate with lower restoration accuracy?\n",
    ">\n",
    "> Steps:\n",
    ">\n",
    "> - Clearly state null and alternative hypotheses.\n",
    "> - Perform t-tests or ANOVA where applicable.\n",
    "> - Conduct power analysis to ensure sufficient sample size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence intervals\n",
    "\n",
    "> - Build confidence intervals for parameters like mean restoration error or average noise level.\n",
    "> - Provide interpretations specific to the context of image deblurring.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression and correlation analysis\n",
    "\n",
    "> 1. Analyze correlations between variables:\n",
    ">\n",
    "> - Blur intensity vs. restoration error.\n",
    "> - Noise level vs. restoration accuracy.\n",
    ">\n",
    "> 2. Build a multiple linear regression model:\n",
    ">\n",
    "> - Response Variable: Restoration error.\n",
    "> - Predictors: Blur intensity, noise level, and blur type.\n",
    ">\n",
    "> 3. Validate assumptions using residual analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "> Summarize findings such as:\n",
    ">\n",
    "> - Key factors influencing restoration accuracy.\n",
    "> - Statistical evidence supporting the superiority of certain methods over others.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Citations\n",
    "\n",
    "- [1] https://arxiv.org/abs/2306.05390\n",
    "- [2] https://openaccess.thecvf.com/content/CVPR2023W/NTIRE/html/Li_LSDIR_A_Large_Scale_Dataset_for_Image_Restoration_CVPRW_2023_paper.html\n",
    "- [3] https://github.com/HDCVLab/MC-Blur-Dataset\n",
    "- [4] https://github.com/littleYaang/HQ-50K\n",
    "- [5] https://openaccess.thecvf.com/content/CVPR2023W/NTIRE/papers/Li_LSDIR_A_Large_Scale_Dataset_for_Image_Restoration_CVPRW_2023_paper.pdf\n",
    "- [6] https://huggingface.co/datasets/YangQiee/HQ-50K\n",
    "- [7] https://github.com/ofsoundof/LSDIR\n",
    "- [8] https://paperswithcode.com/author/dongdong-chen\n",
    "- [9] https://paperswithcode.com/datasets?task=image-restoration\n",
    "- [10] https://www.kaggle.com/datasets/ravirajsinh45/real-life-industrial-dataset-of-casting-product\n",
    "- [11] https://openreview.net/forum?id=6eoGVqMiIj\n",
    "- [12] https://github.com/subeeshvasu/Awesome-Deblurring\n",
    "- [13] https://paperswithcode.com/datasets?task=image-quality-assessment\n",
    "- [14] https://paperswithcode.com/task/image-restoration/codeless\n",
    "- [15] https://paperswithcode.com/dataset/gopro\n",
    "- [16] https://www.researchgate.net/publication/349818385_A_Document_Image_Dataset_for_Quality_Assessment\n",
    "- [17] https://github.com/Algolzw/daclip-uir\n",
    "- [18] https://paperswithcode.com/task/image-restoration\n",
    "- [19] http://people.ee.ethz.ch/~ihnatova/\n",
    "- [20] https://data.vision.ee.ethz.ch/cvl/ntire19/\n",
    "- [21] https://diec.unizar.es/intranet/articulos/uploads/Blurred%20Image%20Restoration%20Using%20the%20Type%20of%20Blur%20and%20Blur%20Parameters%20Identification%20on%20the%20Neural%20Network.pdf\n",
    "- [22] https://www.semanticscholar.org/paper/Real-World-Blur-Dataset-for-Learning-and-Deblurring-Rim-Chwa/2d6c14023087b5d5bd90a88da13e0fa765418d84\n",
    "- [23] https://www.researchgate.net/publication/371414316_HQ-50K_A_Large-scale_High-quality_Dataset_for_Image_Restoration\n",
    "- [24] https://huggingface.co/ofsoundof/LSDIR\n",
    "- [25] https://www.researchgate.net/publication/374207157_MC-Blur_A_Comprehensive_Benchmark_for_Image_Deblurring\n",
    "- [26] https://openreview.net/revisions?id=Itug6LHDMR3\n",
    "- [27] https://ieeexplore.ieee.org/document/10208419/\n",
    "- [28] https://dl.acm.org/doi/abs/10.1109/TCSVT.2023.3319330\n",
    "- [29] https://dblp.org/rec/journals/corr/abs-2306-05390\n",
    "- [30] https://ieeexplore.ieee.org/iel7/10208270/10208119/10208419.pdf\n",
    "- [31] https://paperswithcode.com/task/deblurring?page=4\n",
    "- [32] https://www.arxiv-sanity-lite.com/?rank=pid&pid=2303.06994\n",
    "- [33] https://www.computer.org/csdl/proceedings-article/cvprw/2023/024900b775/1PBxOctTkBy\n",
    "- [34] https://arxiv.org/abs/2112.00234\n",
    "- [35] https://paperswithcode.com/datasets?task=image-generation\n",
    "- [36] https://www.semanticscholar.org/paper/05b09817b11cbfb3ba55b6fe8580fd488077d733\n",
    "- [37] https://www.linkedin.com/pulse/your-data-science-projects-here-30-free-datasets-paresh-patil-qin6f\n",
    "- [38] https://arxiv.org/html/2409.00768v1\n",
    "- [39] https://www.researchgate.net/figure/Some-visualizations-of-the-test-results-on-the-MC-Blur-dataset-44-a-Input-images-b_fig8_377558441\n",
    "- [40] https://www.lexjansen.com/nesug/nesug97/advtut/horwitz.pdf\n",
    "- [41] https://stackoverflow.com/questions/68841814/viewing-dataset-in-rstudio-shows-different-number-of-observations-compared-to-r\n",
    "- [42] https://www.nature.com/articles/s41598-023-47768-4\n",
    "- [43] https://www.picsellia.com/post/image-data-quality-for-image-classification\n",
    "- [44] https://arxiv.org/abs/2412.19479\n",
    "- [45] https://supervisely.com/blog/dataset-quality-assurance-and-interactive-statistics/\n",
    "- [46] https://communities.sas.com/t5/SAS-Data-Science/How-to-explore-a-dataset-with-over-3-million-rows/td-p/163318\n",
    "- [47] https://www.statalist.org/forums/forum/general-stata-discussion/general/1680968-how-do-i-know-which-variables-uniquely-identify-each-observation-in-the-dataset-from-a-total-of-134-variables-in-my-dataset\n",
    "- [48] https://pmc.ncbi.nlm.nih.gov/articles/PMC7227093/\n",
    "- [49] https://support.sas.com/resources/papers/proceedings/proceedings/sugi30/061-30.pdf\n",
    "- [50] https://r4ds.hadley.nz/data-tidy.html\n",
    "- [51] https://www.superannotate.com/blog/public-datasets-for-machine-learning\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
