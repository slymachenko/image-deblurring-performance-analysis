{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27d12ec8",
   "metadata": {},
   "source": [
    "The \"HQ-50K Dataset\" is required, which contains the `test` and `train` folders. The important folder is `test`, which includes `.txt` files containing URLs for 1250 images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f837481a",
   "metadata": {},
   "source": [
    "### Load HQ-50k test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74940a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total processed images: 1250\n",
      "                                                    url  category\n",
      "0     https://prosperwell.com/wp-content/uploads/201...    animal\n",
      "1     https://jennifertarheelreader.files.wordpress....    animal\n",
      "2     http://lanting.com/wp-content/uploads/Lanting_...    animal\n",
      "3     https://drscdn.500px.org/photo/41458556/m%3D20...    animal\n",
      "4     https://images7.alphacoders.com/755/thumb-1920...    animal\n",
      "...                                                 ...       ...\n",
      "1245  https://images.squarespace-cdn.com/content/v1/...  withchar\n",
      "1246  https://s3-us-west-2.amazonaws.com/static1.vil...  withchar\n",
      "1247  https://greeblehaus.com/wp-content/uploads/201...  withchar\n",
      "1248  http://media3.onsugar.com/files/2013/12/06/901...  withchar\n",
      "1249  http://www.fontpad.co.uk/wp-content/uploads/20...  withchar\n",
      "\n",
      "[1250 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# create df with \"url\" and \"category\"\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "dataset_path = \"../../data/HQ-50k/test\"\n",
    "image_data = []\n",
    "\n",
    "# Iterate over .txt files in the folder\n",
    "for txt_file in os.listdir(dataset_path):\n",
    "    if txt_file.endswith(\".txt\"):\n",
    "        category = os.path.splitext(txt_file)[0]  # Use the file name (without extension) as the category\n",
    "        txt_path = os.path.join(dataset_path, txt_file)\n",
    "        with open(txt_path, \"r\") as file:\n",
    "            urls = file.readlines()\n",
    "\n",
    "            for url in urls:\n",
    "                url = url.strip()\n",
    "                if not url:\n",
    "                    continue\n",
    "\n",
    "                image_data.append({\n",
    "                    \"url\": url,\n",
    "                    \"category\": category\n",
    "                })\n",
    "\n",
    "# Verify the total number of images, must be 1250\n",
    "print(f\"Total processed images: {len(image_data)}\")\n",
    "\n",
    "df_image_data = pd.DataFrame(image_data)\n",
    "print(df_image_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6585fb8d",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bfb8ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verify URLs: 100%|██████████| 1250/1250 [01:21<00:00, 15.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   url category\n",
      "0    https://prosperwell.com/wp-content/uploads/201...   animal\n",
      "1    https://jennifertarheelreader.files.wordpress....   animal\n",
      "2    http://lanting.com/wp-content/uploads/Lanting_...   animal\n",
      "3    https://drscdn.500px.org/photo/41458556/m%3D20...   animal\n",
      "4    https://images7.alphacoders.com/755/thumb-1920...   animal\n",
      "..                                                 ...      ...\n",
      "927  https://www.williamhortonphotography.com/wp-co...  vehicle\n",
      "928  http://media4.onsugar.com/files/2014/01/12/123...  vehicle\n",
      "929  https://amsrus.ru/wp-content/uploads/2017/01/b...  vehicle\n",
      "930            https://i.postimg.cc/JzD5v86M/10024.jpg  vehicle\n",
      "931            https://i.postimg.cc/LsjB4TFW/10031.jpg  vehicle\n",
      "\n",
      "[932 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# validate URLs\n",
    "from concurrent.futures import ThreadPoolExecutor       # for parallel processing\n",
    "import requests                                         # for HTTP requests\n",
    "from tqdm import tqdm                                   # for progress bar\n",
    "\n",
    "# Function to verify a single URL\n",
    "def is_valid_url(url):\n",
    "    try:\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "        }\n",
    "        response = requests.head(url, timeout=15, headers=headers, allow_redirects=True)\n",
    "        return response.status_code == 200\n",
    "    except requests.RequestException:\n",
    "        return False\n",
    "\n",
    "# Function to process a row of the DataFrame\n",
    "def process_row(row):\n",
    "    if is_valid_url(row['url']):\n",
    "        # Return a dictionary containing the unique ID, URL, and category for valid image URLs\n",
    "        return {\n",
    "            'url': row['url'],  # URL of the image\n",
    "            'category': row['category']  # Category of the image\n",
    "        }\n",
    "    return None\n",
    "\n",
    "# Verify URLs in parallel\n",
    "valid_image_data = []\n",
    "with ThreadPoolExecutor(max_workers=8) as executor:  # Use 8 threads to parallelize\n",
    "    futures = list(tqdm(executor.map(process_row, [row for _, row in df_image_data.iterrows()]), total=len(df_image_data), desc=\"Verify URLs\"))\n",
    "    valid_image_data = [result for result in futures if result is not None]\n",
    "\n",
    "# Create the new DataFrame\n",
    "df_valid_image_data = pd.DataFrame(valid_image_data)\n",
    "df_valid_image_data = df_valid_image_data[df_valid_image_data['category'] != 'withchar'] # Exclude 'withchar' category because it has few images\n",
    "\n",
    "# Display the result\n",
    "print(df_valid_image_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163d6762",
   "metadata": {},
   "source": [
    "### 'image_deblurring_dataset.csv' creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4da9a111",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 118/932 [00:12<01:28,  9.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing URL https://www.gilingo.de/wp-content/uploads/2017/07/iStock-648821756-Edit-Final-darker.jpg: Failed to decode image with OpenCV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 287/932 [00:25<00:40, 15.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing URL https://www.dreampirates.in/wallpaper/textures/img/25-12-2019-1674-wood-surface-texture-boards.jpg: Failed to decode image with OpenCV\n",
      "Error processing URL https://www.all4women.co.za/wp-content/uploads/2021/04/15/Nandos2484.jpg: Failed to decode image with OpenCV\n",
      "Error processing URL https://media2.fdncms.com/eastbayexpress/imager/u/original/12065784/img_0623.jpg: Failed to decode image with OpenCV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 394/932 [00:38<00:41, 13.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing URL https://www.adelaidehillswinetrail.com/wp-content/uploads/2015/01/vintage-peacock-wall-art.jpg: Failed to decode image with OpenCV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 599/932 [01:01<00:32, 10.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing URL https://www.cartographersguild.com/attachment.php?attachmentid=42083: Failed to decode image with OpenCV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 617/932 [01:03<00:31, 10.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing URL https://img.kansasmemory.org/00278033.jpg: Failed to decode image with OpenCV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 621/932 [01:03<00:29, 10.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing URL http://cascoly.com/maps/map-1965-world.jpg: Failed to decode image with OpenCV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 656/932 [01:12<01:34,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing URL https://kerrymorgan.com/wp-content/uploads/2017/08/2017-08-22_0029.jpg: Failed to decode image with OpenCV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 932/932 [01:38<00:00,  9.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata saved to ../../data/image_deblurring_dataset.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from io import BytesIO\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "# Add an 'id' column to the DataFrame\n",
    "df_valid_image_data['id'] = range(1, len(df_valid_image_data) + 1)\n",
    "\n",
    "# Function to process a single image and extract metadata\n",
    "def extract_image_metadata(row):\n",
    "    \"\"\"\n",
    "    Fetches an image from the URL and extracts metadata like width, height,\n",
    "    format, aspect ratio, and size.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        url = row['url']\n",
    "        # Perform the full GET request to fetch the image\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "        }\n",
    "        response = requests.get(url, timeout=20, headers=headers, allow_redirects=True)\n",
    "        response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "        size = len(response.content)  # Image size in bytes\n",
    "\n",
    "        # Open the image with OpenCV\n",
    "        image_array = np.asarray(bytearray(response.content), dtype=np.uint8)\n",
    "        image = cv2.imdecode(image_array, cv2.IMREAD_COLOR)\n",
    "        if image is None:\n",
    "            raise ValueError(\"Failed to decode image with OpenCV\")\n",
    "\n",
    "        # Extract metadata using OpenCV\n",
    "        height, width, _ = image.shape\n",
    "        aspect_ratio = round(width / height, 2)\n",
    "\n",
    "        # Use Pillow to detect the image format\n",
    "        image_format = Image.open(BytesIO(response.content)).format\n",
    "\n",
    "        # Return all metadata\n",
    "        return {\n",
    "            'id': row['id'],  # Include the ID\n",
    "            'category': row['category'],\n",
    "            'width': width,\n",
    "            'height': height,\n",
    "            'format': image_format,\n",
    "            'aspect_ratio': aspect_ratio,\n",
    "            'size': size,\n",
    "            'url': url  # Move URL to the last column\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing URL {row['url']}: {e}\")\n",
    "        # Return NaN for all metadata fields in case of an error\n",
    "        return {\n",
    "            'id': row['id'],  # Include the ID even in case of failure\n",
    "            'category': row['category'],\n",
    "            'width': np.nan,\n",
    "            'height': np.nan,\n",
    "            'format': np.nan,\n",
    "            'aspect_ratio': np.nan,\n",
    "            'size': np.nan,\n",
    "            'url': row['url']  # Ensure the URL is preserved\n",
    "        }\n",
    "\n",
    "# Parallelize metadata extraction\n",
    "def process_metadata_in_parallel(df, max_workers=8):\n",
    "    \"\"\"\n",
    "    Processes images in parallel using ThreadPoolExecutor for efficiency.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Map dataframe rows to the extract_image_metadata function\n",
    "        futures = list(tqdm(executor.map(extract_image_metadata, [row for _, row in df.iterrows()]), total=len(df)))\n",
    "        results.extend(futures)\n",
    "    return results\n",
    "\n",
    "# Extract metadata for all valid images in parallel\n",
    "image_metadata = process_metadata_in_parallel(df_valid_image_data)\n",
    "\n",
    "# Create a DataFrame with the metadata\n",
    "df_metadata = pd.DataFrame(image_metadata)\n",
    "\n",
    "# Save the DataFrame to a CSV file (ensure proper quoting for all fields)\n",
    "output_path = \"../../data/image_deblurring_dataset.csv\"\n",
    "df_metadata.to_csv(output_path, index=False, quoting=1)  # quoting=1 ensures all fields are quoted\n",
    "\n",
    "print(f\"Metadata saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfd1ac1",
   "metadata": {},
   "source": [
    "### Check standard deviation of images per category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "612eb0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category\n",
      "animal          94\n",
      "architecture    74\n",
      "comic           90\n",
      "complex         75\n",
      "food            76\n",
      "furniture       70\n",
      "indoor_scene    69\n",
      "map             81\n",
      "people          74\n",
      "poster          83\n",
      "scenery         65\n",
      "vehicle         72\n",
      "Name: id, dtype: int64\n",
      "\n",
      "Sum of counts: 923\n",
      "\n",
      "Standard deviation of the number of images per category: 8.240735538908053\n"
     ]
    }
   ],
   "source": [
    "# Calculate the standard deviation of the number of images per category\n",
    "\n",
    "# Filter the DataFrame to exclude rows with NaN values\n",
    "df_filtered = df_metadata.dropna()\n",
    "\n",
    "# Group the filtered DataFrame by category and count the number of images per category\n",
    "category_counts = df_filtered.groupby('category')['id'].count()\n",
    "print(category_counts)\n",
    "sum_counts = category_counts.sum()\n",
    "print(f\"\\nSum of counts: {sum_counts}\\n\")\n",
    "\n",
    "# Calculate the standard deviation of the counts\n",
    "std_dev = np.std(category_counts)\n",
    "\n",
    "# Print the result\n",
    "print(f\"Standard deviation of the number of images per category: {std_dev}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
