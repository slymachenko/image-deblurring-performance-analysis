{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27d12ec8",
   "metadata": {},
   "source": [
    "The \"HQ-50K Dataset\" is required, which contains the `test` and `train` folders. The important folder is `test`, which includes `.txt` files containing URLs for 1250 images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f837481a",
   "metadata": {},
   "source": [
    "### Load HQ-50k test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74940a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total processed images: 1250\n",
      "                                                    url  category\n",
      "0     https://prosperwell.com/wp-content/uploads/201...    animal\n",
      "1     https://jennifertarheelreader.files.wordpress....    animal\n",
      "2     http://lanting.com/wp-content/uploads/Lanting_...    animal\n",
      "3     https://drscdn.500px.org/photo/41458556/m%3D20...    animal\n",
      "4     https://images7.alphacoders.com/755/thumb-1920...    animal\n",
      "...                                                 ...       ...\n",
      "1245  https://images.squarespace-cdn.com/content/v1/...  withchar\n",
      "1246  https://s3-us-west-2.amazonaws.com/static1.vil...  withchar\n",
      "1247  https://greeblehaus.com/wp-content/uploads/201...  withchar\n",
      "1248  http://media3.onsugar.com/files/2013/12/06/901...  withchar\n",
      "1249  http://www.fontpad.co.uk/wp-content/uploads/20...  withchar\n",
      "\n",
      "[1250 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# create df with \"url\" and \"category\"\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "dataset_path = \"../../data/HQ-50k/test\"\n",
    "image_data = []\n",
    "\n",
    "# Iterate over .txt files in the folder\n",
    "for txt_file in os.listdir(dataset_path):\n",
    "    if txt_file.endswith(\".txt\"):\n",
    "        category = os.path.splitext(txt_file)[0]  # Use the file name (without extension) as the category\n",
    "        txt_path = os.path.join(dataset_path, txt_file)\n",
    "        with open(txt_path, \"r\") as file:\n",
    "            urls = file.readlines()\n",
    "\n",
    "            for url in urls:\n",
    "                url = url.strip()\n",
    "                if not url:\n",
    "                    continue\n",
    "\n",
    "                image_data.append({\n",
    "                    \"url\": url,\n",
    "                    \"category\": category\n",
    "                })\n",
    "\n",
    "# Verify the total number of images, must be 1250\n",
    "print(f\"Total processed images: {len(image_data)}\")\n",
    "\n",
    "df_image_data = pd.DataFrame(image_data)\n",
    "print(df_image_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6585fb8d",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5bfb8ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verify URLs: 100%|██████████| 1250/1250 [01:10<00:00, 17.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   url category\n",
      "0    https://prosperwell.com/wp-content/uploads/201...   animal\n",
      "1    https://jennifertarheelreader.files.wordpress....   animal\n",
      "2    http://lanting.com/wp-content/uploads/Lanting_...   animal\n",
      "3    https://drscdn.500px.org/photo/41458556/m%3D20...   animal\n",
      "4    https://images7.alphacoders.com/755/thumb-1920...   animal\n",
      "..                                                 ...      ...\n",
      "905  https://www.williamhortonphotography.com/wp-co...  vehicle\n",
      "906  http://media4.onsugar.com/files/2014/01/12/123...  vehicle\n",
      "907  https://amsrus.ru/wp-content/uploads/2017/01/b...  vehicle\n",
      "908            https://i.postimg.cc/JzD5v86M/10024.jpg  vehicle\n",
      "909            https://i.postimg.cc/LsjB4TFW/10031.jpg  vehicle\n",
      "\n",
      "[910 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# validate URLs\n",
    "from concurrent.futures import ThreadPoolExecutor       # for parallel processing\n",
    "import requests                                         # for HTTP requests\n",
    "from tqdm import tqdm                                   # for progress bar\n",
    "\n",
    "# Function to verify a single URL and ensure it points to a valid image\n",
    "def is_valid_image_url(url):\n",
    "    try:\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "        }\n",
    "        response = requests.head(url, timeout=20, headers=headers, allow_redirects=True)\n",
    "        \n",
    "        # Check if the status code is 200 and the Content-Type is an image\n",
    "        if response.status_code == 200 and 'image' in response.headers.get('Content-Type', ''):\n",
    "            return True\n",
    "        return False\n",
    "    except requests.RequestException:\n",
    "        return False\n",
    "\n",
    "# Function to process a row of the DataFrame\n",
    "def process_row(row):\n",
    "    if is_valid_image_url(row['url']):\n",
    "        # Return a dictionary containing the unique ID, URL, and category for valid image URLs\n",
    "        return {\n",
    "            'url': row['url'],  # URL of the image\n",
    "            'category': row['category']  # Category of the image\n",
    "        }\n",
    "    return None\n",
    "\n",
    "# Verify URLs in parallel\n",
    "valid_image_data = []\n",
    "with ThreadPoolExecutor(max_workers=8) as executor:  # Use 8 threads to parallelize\n",
    "    futures = list(tqdm(executor.map(process_row, [row for _, row in df_image_data.iterrows()]), total=len(df_image_data), desc=\"Verify URLs\"))\n",
    "    valid_image_data = [result for result in futures if result is not None]\n",
    "\n",
    "# Create the new DataFrame\n",
    "df_valid_image_data = pd.DataFrame(valid_image_data)\n",
    "df_valid_image_data = df_valid_image_data[df_valid_image_data['category'] != 'withchar'] # Exclude 'withchar' category because it has few images\n",
    "\n",
    "# Display the result\n",
    "print(df_valid_image_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163d6762",
   "metadata": {},
   "source": [
    "### 'image_deblurring_dataset.csv' creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da9a111",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting metadata:  36%|███▌      | 325/910 [00:21<00:31, 18.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing URL https://danieletorella.com/wp-content/uploads/2017/06/wedding-castello-meleto-toscana-0044.jpg: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error processing URL https://www.demetriopaparoni.com/image.php?rand=1597401839&t=p&id=18&o=1: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting metadata:  47%|████▋     | 431/910 [00:37<00:41, 11.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing URL https://stillmed.olympic.org/media/Images/OlympicOrg/News/2019/12/03/2019-12-03-EB-fight-against-doping-thumbnail.jpg: HTTPSConnectionPool(host='stillmed.olympic.org', port=443): Read timed out. (read timeout=20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting metadata: 100%|██████████| 910/910 [00:49<00:00, 18.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata saved to ../../data/image_deblurring_dataset.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# set ids and metadata\n",
    "# save in `image_deblurring_dataset.csv`\n",
    "\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "\n",
    "# Function to extract image metadata\n",
    "def extract_image_metadata(row, unique_id):\n",
    "    try:\n",
    "        response = requests.get(row['url'], timeout=20)\n",
    "        if response.status_code == 200:\n",
    "            img = Image.open(BytesIO(response.content))\n",
    "            width, height = img.size\n",
    "            aspect_ratio = width / height\n",
    "            size = len(response.content)  # Size in bytes\n",
    "            return {\n",
    "                'id': unique_id,  # Unique ID starting from 1\n",
    "                'width': width,\n",
    "                'height': height,\n",
    "                'aspect_ratio': aspect_ratio,\n",
    "                'format': img.format,\n",
    "                'size': size,  # Weight of the image in bytes\n",
    "                'category': row['category'],\n",
    "                'url': row['url']\n",
    "            }\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing URL {row['url']}: {e}\")\n",
    "        # Return NaN for all metadata fields in case of an error\n",
    "        return {\n",
    "            'id': unique_id,\n",
    "            'width': np.nan,\n",
    "            'height': np.nan,\n",
    "            'aspect_ratio': np.nan,\n",
    "            'format': np.nan,\n",
    "            'size': np.nan,\n",
    "            'category': row['category'],\n",
    "            'url': row['url']\n",
    "        }\n",
    "\n",
    "# Parallelize metadata extraction\n",
    "def process_metadata_in_parallel(df, max_workers=8):\n",
    "    image_metadata = []\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = list(tqdm(\n",
    "            executor.map(lambda args: extract_image_metadata(args[1], args[0]),  # Pass row as a dictionary\n",
    "                         [(idx, row.to_dict()) for idx, row in df.iterrows()]),  # Convert row to dictionary\n",
    "            total=len(df), desc=\"Extracting metadata\"\n",
    "        ))\n",
    "    for result in futures:\n",
    "        if result is not None:\n",
    "            image_metadata.append(result)\n",
    "    return image_metadata\n",
    "\n",
    "# Extract metadata for all valid images in parallel\n",
    "image_metadata = process_metadata_in_parallel(df_valid_image_data)\n",
    "\n",
    "# Create a DataFrame with the metadata\n",
    "df_metadata = pd.DataFrame(image_metadata)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "output_path = \"../../data/image_deblurring_dataset.csv\"\n",
    "df_metadata.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Metadata saved to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
